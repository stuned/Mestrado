{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69950d7e-39df-41f6-9438-229c7afdb714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>language</th>\n",
       "      <th>id_if_retweetd_tweet</th>\n",
       "      <th>íd_if_quoted_tweet</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-16 23:59:23+00:00</td>\n",
       "      <td>710254163003723777</td>\n",
       "      <td>Gonna see 10 Cloverfield Lane tonight with out...</td>\n",
       "      <td>ejwaree</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Cloverfield-Lane-sem-retweet.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-16 23:59:18+00:00</td>\n",
       "      <td>710254143647162369</td>\n",
       "      <td>I'm at the movies about to watch 10 Cloverfiel...</td>\n",
       "      <td>SaraParamo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Cloverfield-Lane-sem-retweet.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-16 23:59:13+00:00</td>\n",
       "      <td>710254123116011520</td>\n",
       "      <td>Seeing 10 Cloverfield Lane (@ Plymouth Grand 1...</td>\n",
       "      <td>NickBarrett</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Cloverfield-Lane-sem-retweet.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-03-16 23:57:52+00:00</td>\n",
       "      <td>710253782005895168</td>\n",
       "      <td>Movie Review of 10 Cloverfield Lane! #10Clover...</td>\n",
       "      <td>DGoodBiscuits</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Cloverfield-Lane-sem-retweet.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-03-16 23:57:01+00:00</td>\n",
       "      <td>710253570952712192</td>\n",
       "      <td>TOP 5 Paris:  1-DIVERGENTE 3: AU-DELA  DU MUR ...</td>\n",
       "      <td>cSMoviesFrance</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Cloverfield-Lane-sem-retweet.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                   Datetime            Tweet Id  \\\n",
       "0          0  2016-03-16 23:59:23+00:00  710254163003723777   \n",
       "1          1  2016-03-16 23:59:18+00:00  710254143647162369   \n",
       "2          2  2016-03-16 23:59:13+00:00  710254123116011520   \n",
       "3          3  2016-03-16 23:57:52+00:00  710253782005895168   \n",
       "4          4  2016-03-16 23:57:01+00:00  710253570952712192   \n",
       "\n",
       "                                                Text        Username  \\\n",
       "0  Gonna see 10 Cloverfield Lane tonight with out...         ejwaree   \n",
       "1  I'm at the movies about to watch 10 Cloverfiel...      SaraParamo   \n",
       "2  Seeing 10 Cloverfield Lane (@ Plymouth Grand 1...     NickBarrett   \n",
       "3  Movie Review of 10 Cloverfield Lane! #10Clover...   DGoodBiscuits   \n",
       "4  TOP 5 Paris:  1-DIVERGENTE 3: AU-DELA  DU MUR ...  cSMoviesFrance   \n",
       "\n",
       "  reply_count retweet_count like_count quote_count language  \\\n",
       "0           2             0          1           0       en   \n",
       "1           1             2          5           0       en   \n",
       "2           0             0          0           0       en   \n",
       "3           0             0          0           0       en   \n",
       "4           0             1          0           0       en   \n",
       "\n",
       "  id_if_retweetd_tweet íd_if_quoted_tweet                             filename  \n",
       "0                  NaN                NaN  10-Cloverfield-Lane-sem-retweet.csv  \n",
       "1                  NaN                NaN  10-Cloverfield-Lane-sem-retweet.csv  \n",
       "2                  NaN                NaN  10-Cloverfield-Lane-sem-retweet.csv  \n",
       "3                  NaN                NaN  10-Cloverfield-Lane-sem-retweet.csv  \n",
       "4                  NaN                NaN  10-Cloverfield-Lane-sem-retweet.csv  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweets = pd.read_csv ('tweets completos.csv', dtype = {'Unnamed: 0': str, 'Datetime': str, 'Tweet Id': str, 'Text': str, 'Username': str, 'reply_count': str, 'retweet_count': str,\n",
    "                                                         'like_count': str, 'quote_count': str, 'language': str, 'id_if_retweetd_tweet': str, 'id_if_quoted_tweet': str, 'filename': str},\n",
    "                    engine='python',encoding='utf-8', on_bad_lines='skip')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ecb242-8258-42e0-81ed-f1417b1bcd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         Unnamed: 0                   Datetime            Tweet Id  \\\n",
       "0                0  2016-03-16 23:59:23+00:00  710254163003723777   \n",
       "1                1  2016-03-16 23:59:18+00:00  710254143647162369   \n",
       "2                2  2016-03-16 23:59:13+00:00  710254123116011520   \n",
       "3                3  2016-03-16 23:57:52+00:00  710253782005895168   \n",
       "4                4  2016-03-16 23:57:01+00:00  710253570952712192   \n",
       "...            ...                        ...                 ...   \n",
       "4952417    5331985  2013-06-21 20:14:19+00:00  348172045898633216   \n",
       "4952418    5331986  2013-06-21 20:14:18+00:00  348172043461746688   \n",
       "4952419    5331987  2013-06-21 20:14:14+00:00  348172028542611456   \n",
       "4952420    5331988  2013-06-21 20:14:14+00:00  348172027317846016   \n",
       "4952421    5331989  2013-06-21 20:14:14+00:00  348172025069723649   \n",
       "\n",
       "                                                      Text        Username  \\\n",
       "0        Gonna see 10 Cloverfield Lane tonight with out...         ejwaree   \n",
       "1        I'm at the movies about to watch 10 Cloverfiel...      SaraParamo   \n",
       "2        Seeing 10 Cloverfield Lane (@ Plymouth Grand 1...     NickBarrett   \n",
       "3        Movie Review of 10 Cloverfield Lane! #10Clover...   DGoodBiscuits   \n",
       "4        TOP 5 Paris:  1-DIVERGENTE 3: AU-DELA  DU MUR ...  cSMoviesFrance   \n",
       "...                                                    ...             ...   \n",
       "4952417  Just saw World War Z with Hunter. Craziest mov...        CEGearon   \n",
       "4952418  Saw the new and awesome movie World War Z toda...   MothChanOffic   \n",
       "4952419     I wasn't expecting world war z to be that good   clairenewmann   \n",
       "4952420                Yea imma go see world war Z tonight    Sir_FishAlot   \n",
       "4952421                               World war z #amazing    nikki_slater   \n",
       "\n",
       "        reply_count retweet_count like_count quote_count language  \\\n",
       "0                 2             0          1           0       en   \n",
       "1                 1             2          5           0       en   \n",
       "2                 0             0          0           0       en   \n",
       "3                 0             0          0           0       en   \n",
       "4                 0             1          0           0       en   \n",
       "...             ...           ...        ...         ...      ...   \n",
       "4952417           0             0          1           0       en   \n",
       "4952418           0             0          0           0       en   \n",
       "4952419           0             0          4           0       en   \n",
       "4952420           0             0          0           0       en   \n",
       "4952421           0             0          0           0       en   \n",
       "\n",
       "        id_if_retweetd_tweet íd_if_quoted_tweet  \\\n",
       "0                        NaN                NaN   \n",
       "1                        NaN                NaN   \n",
       "2                        NaN                NaN   \n",
       "3                        NaN                NaN   \n",
       "4                        NaN                NaN   \n",
       "...                      ...                ...   \n",
       "4952417                  NaN                NaN   \n",
       "4952418                  NaN                NaN   \n",
       "4952419                  NaN                NaN   \n",
       "4952420                  NaN                NaN   \n",
       "4952421                  NaN                NaN   \n",
       "\n",
       "                                    filename  \n",
       "0        10-Cloverfield-Lane-sem-retweet.csv  \n",
       "1        10-Cloverfield-Lane-sem-retweet.csv  \n",
       "2        10-Cloverfield-Lane-sem-retweet.csv  \n",
       "3        10-Cloverfield-Lane-sem-retweet.csv  \n",
       "4        10-Cloverfield-Lane-sem-retweet.csv  \n",
       "...                                      ...  \n",
       "4952417          World-War-Z-sem-retweet.csv  \n",
       "4952418          World-War-Z-sem-retweet.csv  \n",
       "4952419          World-War-Z-sem-retweet.csv  \n",
       "4952420          World-War-Z-sem-retweet.csv  \n",
       "4952421          World-War-Z-sem-retweet.csv  \n",
       "\n",
       "[4952422 rows x 13 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb8ed7c-904b-4807-b1a8-64d1901c23f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         Unnamed: 0                   Datetime            Tweet Id  \\\n",
       "0                0  2016-03-16 23:59:23+00:00  710254163003723777   \n",
       "1                1  2016-03-16 23:59:18+00:00  710254143647162369   \n",
       "2                2  2016-03-16 23:59:13+00:00  710254123116011520   \n",
       "3                3  2016-03-16 23:57:52+00:00  710253782005895168   \n",
       "4                4  2016-03-16 23:57:01+00:00  710253570952712192   \n",
       "...            ...                        ...                 ...   \n",
       "4952417    5331985  2013-06-21 20:14:19+00:00  348172045898633216   \n",
       "4952418    5331986  2013-06-21 20:14:18+00:00  348172043461746688   \n",
       "4952419    5331987  2013-06-21 20:14:14+00:00  348172028542611456   \n",
       "4952420    5331988  2013-06-21 20:14:14+00:00  348172027317846016   \n",
       "4952421    5331989  2013-06-21 20:14:14+00:00  348172025069723649   \n",
       "\n",
       "                                                      Text        Username  \\\n",
       "0        Gonna see 10 Cloverfield Lane tonight with out...         ejwaree   \n",
       "1        I'm at the movies about to watch 10 Cloverfiel...      SaraParamo   \n",
       "2        Seeing 10 Cloverfield Lane (@ Plymouth Grand 1...     NickBarrett   \n",
       "3        Movie Review of 10 Cloverfield Lane! #10Clover...   DGoodBiscuits   \n",
       "4        TOP 5 Paris:  1-DIVERGENTE 3: AU-DELA  DU MUR ...  cSMoviesFrance   \n",
       "...                                                    ...             ...   \n",
       "4952417  Just saw World War Z with Hunter. Craziest mov...        CEGearon   \n",
       "4952418  Saw the new and awesome movie World War Z toda...   MothChanOffic   \n",
       "4952419     I wasn't expecting world war z to be that good   clairenewmann   \n",
       "4952420                Yea imma go see world war Z tonight    Sir_FishAlot   \n",
       "4952421                               World war z #amazing    nikki_slater   \n",
       "\n",
       "        reply_count retweet_count like_count quote_count language  \\\n",
       "0                 2             0          1           0       en   \n",
       "1                 1             2          5           0       en   \n",
       "2                 0             0          0           0       en   \n",
       "3                 0             0          0           0       en   \n",
       "4                 0             1          0           0       en   \n",
       "...             ...           ...        ...         ...      ...   \n",
       "4952417           0             0          1           0       en   \n",
       "4952418           0             0          0           0       en   \n",
       "4952419           0             0          4           0       en   \n",
       "4952420           0             0          0           0       en   \n",
       "4952421           0             0          0           0       en   \n",
       "\n",
       "        id_if_retweetd_tweet íd_if_quoted_tweet  \\\n",
       "0                        NaN                NaN   \n",
       "1                        NaN                NaN   \n",
       "2                        NaN                NaN   \n",
       "3                        NaN                NaN   \n",
       "4                        NaN                NaN   \n",
       "...                      ...                ...   \n",
       "4952417                  NaN                NaN   \n",
       "4952418                  NaN                NaN   \n",
       "4952419                  NaN                NaN   \n",
       "4952420                  NaN                NaN   \n",
       "4952421                  NaN                NaN   \n",
       "\n",
       "                                    filename  \n",
       "0        10-Cloverfield-Lane-sem-retweet.csv  \n",
       "1        10-Cloverfield-Lane-sem-retweet.csv  \n",
       "2        10-Cloverfield-Lane-sem-retweet.csv  \n",
       "3        10-Cloverfield-Lane-sem-retweet.csv  \n",
       "4        10-Cloverfield-Lane-sem-retweet.csv  \n",
       "...                                      ...  \n",
       "4952417          World-War-Z-sem-retweet.csv  \n",
       "4952418          World-War-Z-sem-retweet.csv  \n",
       "4952419          World-War-Z-sem-retweet.csv  \n",
       "4952420          World-War-Z-sem-retweet.csv  \n",
       "4952421          World-War-Z-sem-retweet.csv  \n",
       "\n",
       "[4952422 rows x 13 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tweets_test = tweets.head()\n",
    "tweets_test = tweets\n",
    "tweets_test.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79da7a84-6aa9-428b-9fa1-d18e7349960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweetnlp\n",
    "from transformers import pipeline\n",
    "import timeit\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b63021-56fd-4971-b591-18bdfeb6d5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brenn/miniconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/brenn/miniconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_emotion = tweetnlp.load_model('topic_classification', model_name='cardiffnlp/twitter-roberta-base-emotion-multilabel-latest')\n",
    "sentiment_task = tweetnlp.load_model('sentiment', model_name='cardiffnlp/twitter-roberta-base-sentiment-latest')\n",
    "#pipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\", return_all_scores=True)\n",
    "#pipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\")\n",
    "#for row in tweets_test.itertuples(index=True, name='Pandas'): \n",
    "#    print(getattr(row, \"Text\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cf7bda5-0559-4c23-9f25-e92a43c395d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd432c195d04b459fe1c4fb076a1591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress using tqdm_notebook():   0%|          | 0/4952422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     result_emotion\u001b[38;5;241m.\u001b[39mappend(model_emotion\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mgetattr\u001b[39m(row, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m\"\u001b[39m), return_probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m ))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#result.append(pipe(getattr(row, \"Text\")))\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     sleep(\u001b[38;5;241m0.25\u001b[39m)\n\u001b[1;32m      7\u001b[0m tweets_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult_Emotion\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m result_emotion  \n\u001b[1;32m      8\u001b[0m fim_emotion_time \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_emotion = []\n",
    "inicio_emotion_time = timeit.default_timer()\n",
    "for row in tqdm_notebook(tweets_test.itertuples(index=True, name='Pandas'), desc = 'Progress using tqdm_notebook()', total = tweets_test.shape[0]):\n",
    "    result_emotion.append(model_emotion.predict(getattr(row, \"Text\"), return_probability=True ))\n",
    "    #result.append(pipe(getattr(row, \"Text\")))\n",
    "    sleep(0.25)\n",
    "tweets_test[\"Result_Emotion\"] = result_emotion  \n",
    "fim_emotion_time = timeit.default_timer()\n",
    "print ('duracao exec modelo de emoções: %f' % (fim_emotion_time - inicio_emotion_time))\n",
    "print(tweets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbdf25e-3e7f-405e-af66-30f6981d9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sentiment = []\n",
    "inicio_sentiment_time = timeit.default_timer()\n",
    "for row in tqdm_notebook(tweets_test.itertuples(index=True, name='Pandas'), desc = 'Progress using tqdm_notebook()', total = tweets_test.shape[0]):\n",
    "    result_sentiment.append(sentiment_task.predict(getattr(row, \"Text\"), return_probability=True))\n",
    "    #result.append(pipe(getattr(row, \"Text\")))\n",
    "    sleep(0.25)\n",
    "tweets_test[\"Result_Sentiment\"] = result_sentiment\n",
    "fim_sentiment_time = timeit.default_timer()\n",
    "print ('duracao exec modelo de sentimento: %f' % (fim_sentiment_time - inicio_sentimentn_time))\n",
    "print(tweets_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c0f8b-5d87-462b-815e-06eeffd785dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cb983d-81c6-41ec-9852-5bfd0475ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test[\"Result_Emotion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9f037-8a51-4e5d-bc26-3ca7ad7e6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test[\"Result_Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386dcc1b-97a0-4f02-9fe8-0a4a2a40c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dictionary col Result_Emotion\n",
    "tweets_test_split_emotion = tweets_test[\"Result_Emotion\"].apply(pd.Series)\n",
    "tweets_test_split_emotion[\"Tweet Id\"] = tweets_test[\"Tweet Id\"]\n",
    "tweets_test_split_emotion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3422cee-f836-45a7-9eda-725729be474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dictionary col Result_Sentiment\n",
    "tweets_test_split_sentiment = tweets_test[\"Result_Sentiment\"].apply(pd.Series)\n",
    "tweets_test_split_sentiment[\"Tweet Id\"] = tweets_test[\"Tweet Id\"]\n",
    "tweets_test_split_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907bebe-6953-4baf-a438-6bd55b46df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split single column into two columns use apply()\n",
    "tweets_test_split_emotion[['emotion_1', 'emotion_2']] = tweets_test_split_emotion[\"label\"].apply(lambda x: pd.Series(str(x).split(\",\")))\n",
    "print(tweets_test_split_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99030f7-bde7-4483-bd93-b7ff8f896a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test_split_emotion[['emotion_anger', 'emotion_anticipation', 'emotion_disgust', 'emotion_fear', 'emotion_joy', 'emotion_love', 'emotion_optimism', 'emotion_pessimism', 'emotion_sadness', 'emotion_surprise', 'emotion_trust']] = tweets_test_split_emotion[\"probability\"].apply(lambda x: pd.Series(str(x).split(\",\")))\n",
    "print(tweets_test_split_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb5e78-007f-4afb-af9e-6e13135b41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test_split_sentiment[['sentiment_negative', 'sentiment_neutral', 'sentiment_positive']] = tweets_test_split_sentiment[\"probability\"].apply(lambda x: pd.Series(str(x).split(\",\")))\n",
    "print(tweets_test_split_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f2529-0936-4f47-93f5-c71aeaf49619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpando as colunas da parte de emoções\n",
    "tweets_test_split_emotion['emotion_1'] = tweets_test_split_emotion['emotion_1'].str.replace('[', '')\n",
    "tweets_test_split_emotion['emotion_1'] = tweets_test_split_emotion['emotion_1'].str.replace(']', '')\n",
    "tweets_test_split_emotion['emotion_1'] = tweets_test_split_emotion['emotion_1'].str.replace(\"'\", '')\n",
    "tweets_test_split_emotion['emotion_2'] = tweets_test_split_emotion['emotion_2'].str.replace('[', '')\n",
    "tweets_test_split_emotion['emotion_2'] = tweets_test_split_emotion['emotion_2'].str.replace(']', '')\n",
    "tweets_test_split_emotion['emotion_2'] = tweets_test_split_emotion['emotion_2'].str.replace(\"'\", '')\n",
    "tweets_test_split_emotion['emotion_2'] = tweets_test_split_emotion['emotion_2'].fillna(\"\")\n",
    "tweets_test_split_emotion['emotion_anger'] = tweets_test_split_emotion['emotion_anger'].str.replace(\"{'anger': \", '')\n",
    "tweets_test_split_emotion['emotion_anticipation'] = tweets_test_split_emotion['emotion_anticipation'].str.replace(\"'anticipation': \", '')\n",
    "tweets_test_split_emotion['emotion_disgust'] = tweets_test_split_emotion['emotion_disgust'].str.replace(\"'disgust': \", '')\n",
    "tweets_test_split_emotion['emotion_fear'] = tweets_test_split_emotion['emotion_fear'].str.replace(\"'fear': \", '')\n",
    "tweets_test_split_emotion['emotion_joy'] = tweets_test_split_emotion['emotion_joy'].str.replace(\"'joy': \", '')\n",
    "tweets_test_split_emotion['emotion_love'] = tweets_test_split_emotion['emotion_love'].str.replace(\"'love': \", '')\n",
    "tweets_test_split_emotion['emotion_optimism'] = tweets_test_split_emotion['emotion_optimism'].str.replace(\"'optimism': \", '')\n",
    "tweets_test_split_emotion['emotion_pessimism'] = tweets_test_split_emotion['emotion_pessimism'].str.replace(\"'pessimism': \", '')\n",
    "tweets_test_split_emotion['emotion_sadness'] = tweets_test_split_emotion['emotion_sadness'].str.replace(\"'sadness': \", '')\n",
    "tweets_test_split_emotion['emotion_surprise'] = tweets_test_split_emotion['emotion_surprise'].str.replace(\"'surprise': \", '')\n",
    "tweets_test_split_emotion['emotion_trust'] = tweets_test_split_emotion['emotion_trust'].str.replace(\"'trust': \", '')\n",
    "tweets_test_split_emotion['emotion_trust'] = tweets_test_split_emotion['emotion_trust'].str.replace(\"}\", '')\n",
    "print(tweets_test_split_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c604b-ee29-463a-a20a-8bd8c31919e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpando as colunas da parte de sentiment\n",
    "tweets_test_split_sentiment['sentiment_negative'] = tweets_test_split_sentiment['sentiment_negative'].str.replace(\"{'negative': \", '')\n",
    "tweets_test_split_sentiment['sentiment_neutral'] = tweets_test_split_sentiment['sentiment_neutral'].str.replace(\"'neutral': \", '')\n",
    "tweets_test_split_sentiment['sentiment_positive'] = tweets_test_split_sentiment['sentiment_positive'].str.replace(\"'positive': \", '')\n",
    "tweets_test_split_sentiment['sentiment_positive'] = tweets_test_split_sentiment['sentiment_positive'].str.replace(\"}\", '')\n",
    "print(tweets_test_split_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1e624-d406-4bf9-8dd4-93a7d8f1e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando os espaços em brancos dos valores das colunas de emoções\n",
    "tweets_test_split_emotion['emotion_1'] = tweets_test_split_emotion['emotion_1'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion['emotion_2'] = tweets_test_split_emotion['emotion_2'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion['emotion_anger'] = tweets_test_split_emotion['emotion_anger'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion['emotion_anticipation'] = tweets_test_split_emotion['emotion_anticipation'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion['emotion_disgust'] = tweets_test_split_emotion['emotion_disgust'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion['emotion_fear'] = tweets_test_split_emotion['emotion_fear'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion['emotion_joy'] = tweets_test_split_emotion['emotion_joy'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion['emotion_love'] = tweets_test_split_emotion['emotion_love'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion['emotion_optimism'] = tweets_test_split_emotion['emotion_optimism'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion['emotion_pessimism'] = tweets_test_split_emotion['emotion_pessimism'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion['emotion_sadness'] = tweets_test_split_emotion['emotion_sadness'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion['emotion_surprise'] = tweets_test_split_emotion['emotion_surprise'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion['emotion_trust'] = tweets_test_split_emotion['emotion_trust'].apply(lambda x: x.strip())\n",
    "tweets_test_split_emotion = tweets_test_split_emotion.rename(columns={'label': 'emotion', 'probability':'emotion_probability'})\n",
    "print(tweets_test_split_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f217e-4cac-483b-a263-66879aeb8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando os espaços em brancos dos valores das colunas de sentimentos\n",
    "tweets_test_split_sentiment['label'] = tweets_test_split_sentiment['label'].apply(lambda x: x.strip())\n",
    "tweets_test_split_sentiment['sentiment_negative'] = tweets_test_split_sentiment['sentiment_negative'].apply(lambda x: x.strip())\n",
    "tweets_test_split_sentiment['sentiment_neutral'] = tweets_test_split_sentiment['sentiment_neutral'].apply(lambda x: x.strip())\n",
    "tweets_test_split_sentiment['sentiment_positive'] = tweets_test_split_sentiment['sentiment_positive'].apply(lambda x: x.strip())\n",
    "tweets_test_split_sentiment = tweets_test_split_sentiment.rename(columns={'label': 'sentiment', 'probability':'sentiment_probability'})\n",
    "print(tweets_test_split_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693308a9-f0d0-4b60-acbf-3240277fd83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#juntando as colunas novas de emoções na base original\n",
    "tweets_test = tweets_test.merge(tweets_test_split_sentiment, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f238f78-361a-4f9a-ae69-634efe080c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#juntando as colunas novas de sentimentos na base original\n",
    "tweets_test = tweets_test.merge(tweets_test_split_emotion, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd062e-be23-4c06-a105-e85282ec625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deletando uma coluna antiga que nao tem uso\n",
    "del tweets_test[\"Unnamed: 0\"]\n",
    "\n",
    "#limpando a coluna id para nao mostrar os NaN\n",
    "tweets_test['id_if_retweetd_tweet'] = tweets_test['id_if_retweetd_tweet'].fillna(\"\")\n",
    "\n",
    "tweets_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d659772f-cee1-4588-9c6e-465b25ff4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257aaec9-d1ca-45e4-8d3e-9d3829e37674",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa84ec59-3207-4f1f-a6aa-564654c38636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d43d4ac-c394-45f7-983e-dce19e0f02cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test.sentiment.value_counts().plot(kind='bar', title = \"Count of Sentiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92d5ab-afe9-4a88-8061-7d0eba8410b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test_emotion_1 = tweets_test['emotion_1'].value_counts()\n",
    "tweets_test_emotion_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34bd75f-1275-42bb-b1f9-a5d6f8f22487",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test_emotion_2 = tweets_test['emotion_2'].value_counts()\n",
    "tweets_test_emotion_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8a87a7-32c3-4bf2-b6b3-41a3395bc5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test_emotion = tweets_test_emotion_1.add(tweets_test_emotion_2, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55ca73-4357-40b4-b837-8ee8a3d74e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81d094-968f-4821-a72c-0976e6a6cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test_emotion.plot(kind='bar', title ='Count of Emotions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bcb0f7-c2ee-46da-baaf-0d747af780e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test['emotion_1'].value_counts().plot(kind='bar', title ='Count of Emotions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf61782-e62f-408d-b989-c9de100d2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test['emotion_2'].value_counts().plot(kind='bar', title ='Count of Emotions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525800b-554c-48b3-9604-a7a9a7e32d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
